# InnovationLink - Clean Architecture

This repository contains a unified startup-investor platform with intelligent event discovery capabilities.

## ğŸ—ï¸ **Organized Directory Structure**

```
InnovationLink/
â”œâ”€â”€ README.md                          # Main project documentation
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ .venv/                             # Python virtual environment
â”œâ”€â”€ package.json                       # Root package.json for workspace
â”œâ”€â”€ package-lock.json                  # Root package lockfile
â”‚
â”œâ”€â”€ apps/                              # Main applications
â”‚   â”œâ”€â”€ frontend/                      # React frontend application
â”‚   â”‚   â”œâ”€â”€ src/                       # React source code
â”‚   â”‚   â”œâ”€â”€ public/                    # Static assets
â”‚   â”‚   â”œâ”€â”€ package.json               # Frontend dependencies
â”‚   â”‚   â””â”€â”€ vite.config.js             # Vite configuration
â”‚   â”‚
â”‚   â””â”€â”€ backend/                       # Unified backend services
â”‚       â”œâ”€â”€ api/                       # Node.js API server
â”‚       â”‚   â”œâ”€â”€ controllers/           # API controllers
â”‚       â”‚   â”œâ”€â”€ models/                # Data models
â”‚       â”‚   â”œâ”€â”€ routes/                # API routes
â”‚       â”‚   â”œâ”€â”€ middleware/            # Authentication & middleware
â”‚       â”‚   â””â”€â”€ index.js               # Main server file
â”‚       â”‚
â”‚       â”œâ”€â”€ scrapers/                  # Python event scrapers
â”‚       â”‚   â”œâ”€â”€ app.py                 # FastAPI scraper server
â”‚       â”‚   â”œâ”€â”€ database.py            # Database management
â”‚       â”‚   â”œâ”€â”€ models.py              # Data models
â”‚       â”‚   â”œâ”€â”€ new_scrapers.py        # Event scrapers
â”‚       â”‚   â”œâ”€â”€ auto_scraper.py        # Automated scraping
â”‚       â”‚   â”œâ”€â”€ daily_scraper.py       # Scheduled scraping
â”‚       â”‚   â””â”€â”€ static_server.py       # Static file server
â”‚       â”‚
â”‚       â””â”€â”€ static/                    # Bot frontend widgets
â”‚           â”œâ”€â”€ index.html             # Main widget interface
â”‚           â”œâ”€â”€ events.json            # Cached events data
â”‚           â””â”€â”€ *.html                 # Various widget variations
â”‚
â”œâ”€â”€ scripts/                           # Automation & setup scripts
â”‚   â”œâ”€â”€ setup_cron.sh                 # Cron job setup
â”‚   â”œâ”€â”€ setup_react.sh                # React setup automation
â”‚   â”œâ”€â”€ add_sample_data.py             # Database seeding
â”‚   â””â”€â”€ demo.py                        # Demo/testing script
â”‚
â”œâ”€â”€ tests/                             # Test files
â”‚   â”œâ”€â”€ test_nasscom.py                # NASSCOM scraper tests
â”‚   â”œâ”€â”€ test_nasscom_db.py             # Database tests
â”‚   â””â”€â”€ test_scraping.py               # General scraper tests
â”‚
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ ENHANCED_FEATURES.md           # Feature specifications
â”‚   â”œâ”€â”€ MODERN_UI_FEATURES.md          # UI component details
â”‚   â”œâ”€â”€ QUICK_START.md                 # Quick start guide
â”‚   â”œâ”€â”€ REACT_PROPOSAL.md              # React integration proposal
â”‚   â””â”€â”€ README_V2.md                   # Extended documentation
â”‚
â”œâ”€â”€ data/                              # Data storage
â”‚   â””â”€â”€ events.db                      # SQLite events database
â”‚
â””â”€â”€ config/                            # Configuration files
    â”œâ”€â”€ bot-requirements.txt           # Python dependencies
    â””â”€â”€ bot.env.example                # Environment template
```

## ğŸš€ **Getting Started**

### **Frontend Development**
```bash
cd apps/frontend
npm install
npm run dev
# Runs on http://localhost:5173
```

### **Backend API Development**
```bash
cd apps/backend/api
npm install
npm start
# Runs on http://localhost:5001
```

### **Python Scrapers**
```bash
# Install Python dependencies
pip install -r config/bot-requirements.txt

# Configure environment
cp config/bot.env.example .env

# Run scraper server
cd apps/backend/scrapers
python app.py
# Runs on http://localhost:8000

# Run static server
python static_server.py
# Runs on http://localhost:8080
```

### **Database Setup**
```bash
# Run sample data script
python scripts/add_sample_data.py

# Test scrapers
python tests/test_scraping.py
```

## ğŸ”§ **Architecture Benefits**

### **Clean Separation**
- **Frontend**: Pure React application in `apps/frontend/`
- **API**: Node.js authentication & user management in `apps/backend/api/`
- **Scrapers**: Python event collection system in `apps/backend/scrapers/`
- **Static**: Event widgets & interfaces in `apps/backend/static/`

### **Organized Assets**
- **Scripts**: All automation in `scripts/`
- **Tests**: Centralized testing in `tests/`
- **Docs**: All documentation in `docs/`
- **Data**: Database files in `data/`
- **Config**: Environment & dependencies in `config/`

### **Development Workflow**
1. **Frontend changes**: Work in `apps/frontend/`
2. **API changes**: Work in `apps/backend/api/`
3. **Scraper changes**: Work in `apps/backend/scrapers/`
4. **Testing**: Use files in `tests/`
5. **Documentation**: Update files in `docs/`

## ğŸ¯ **Key Features**

### **InnovationLink Platform**
- React-based frontend with modern UI
- Node.js backend with JWT authentication
- User portal for startups and investors
- Dashboard and profile management

### **Event Intelligence System**
- Automated scraping from 7+ sources
- Real-time event collection (30-min cycles)
- FastAPI backend for event APIs
- Multiple widget interfaces
- SQLite database for efficient storage

### **Integration Ready**
- CORS enabled for cross-platform requests
- REST APIs for event data access
- Widget embedding capabilities
- Automated data synchronization

This clean architecture enables independent development while maintaining seamless integration between platform components.